Total pages: 25


--- PAGE 1 ---

Lenartowicz,
 
E.
 
M.
 
(2025).
 
Shaping
 
AI
 
Impacts
 
Through
 
Licensing:
 
Illustrative
 
Scenarios
 
for
 
the
 
Design
 
Space.
 
SSRN
 
–
 
Social
 
Science
 
Research
 
Network.
 
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5835702
 
 
Shaping
 
AI
 
Impacts
 
Through
 
Licensing
 
Illustrative
 
Scenarios
 
for
 
the
 
Design
 
Space
 
 
Dr.
 
Em
 
M.
 
Lenartowicz
 
Free
 
University
 
of
 
Brussels,
 
CLEA
 
(VUB)
 
United
 
Nations,
 
“AI
 
for
 
Good”
 
Impact
 
Initiative
 
–
 
Steering
 
Committee
 
AI
 
Commons
 
Licensing
 
Lab
 
(Pilot
 
Phase)
 
NuNet
 
Foundation
 
 
Abstract
 
Licensing
 
already
 
structures
 
how
 
code,
 
data
 
and
 
models
 
circulate
 
in
 
AI,
 
yet
 
it
 
is
 
rarely
 
treated
 
as
 
a
 
governance
 
instrument.
 
Building
 
on
 
a
 
companion
 
paper
 
that
 
develops
 
six
 
“Commons”
 
logics
 
for
 
impact-oriented
 
AI
 
licensing—Value,
 
Transparency,
 
Sustainability,
 
Access,
 
Reciprocity
 
and
 
Governance—this
 
article
 
turns
 
that
 
design
 
space
 
into
 
concrete
 
scenarios.
 
It
 
shows
 
how
 
clause
 
families
 
could
 
function
 
in
 
practice
 
and
 
spread
 
through
 
procurement,
 
open-source
 
projects,
 
industry
 
consortia
 
and
 
reputational
 
competition.
 
Licensing
 
is
 
presented
 
as
 
a
 
repeatable,
 
enforceable
 
and
 
system-specific
 
layer
 
within
 
the
 
broader
 
governance
 
landscape.
 
The
 
article
 
addresses
 
issues
 
of
 
measurement,
 
standardisation
 
and
 
interactions
 
with
 
competition,
 
data-protection
 
and
 
sectoral
 
rules,
 
and
 
clarifies
 
its
 
use
 
of
 
“Commons”
 
in
 
the
 
digital-commons
 
tradition:
 
small
 
sets
 
of
 
reusable
 
profiles
 
that
 
accumulate
 
into
 
shared
 
resource
 
layers.
 
The
 
contribution
 
is
 
to
 
demonstrate
 
that,
 
once
 
licensing
 
is
 
treated
 
as
 
societal
 
infrastructure,
 
concerns
 
about
 
value,
 
transparency,
 
sustainability,
 
access,
 
reciprocity
 
and
 
governance
 
can
 
be
 
translated
 
into
 
tractable
 
clause
 
families
 
for
 
real
 
deployments.
 
1.
 
Introduction:
 
From
 
Framework
 
to
 
Scenarios
 
The
 
companion
 
paper,
 
Impact-Oriented
 
Licensing
 
for
 
Artificial
 
Intelligence:
 
A
 
Conceptual
 
Framework
 
for
 
a
 
New
 
Domain
 
of
 
AI
 
Governance
 
(Lenartowicz,
 
2025),
 
argues
 
that
 
licensing
 
is
 
part
 
of
 
the
 
societal
 
infrastructure
 
of
 
AI
 
governance:
 
licence
 
terms
 
embed
 
obligations
 
and
 
incentives
 
early
 
in
 
the
 
value
 
chain.
 
On
 
that
 
basis,
 
it
 
introduces
 
six
 
governance
 
logics—Value,
 
Transparency,
 
Sustainability,
 
Access,
 
Reciprocity
 
and
 
Governance
 
Commons—each
 
isolating
 
a
 
dimension
 
of
 
systemic
 
impact.
 
This
 
paper
 
develops
 
the
 
framework
 
through
 
concrete
 
scenarios
 
and
 
provides
 
a
 
catalogue
 
of
 
clause
 
patterns
 
and
 
adoption
 
pathways.
 
It
 
shows
 
how
 
value-sharing,
 
transparency,
 
ecological
 
accounting,
 
 
1
 


--- PAGE 2 ---

 
access
 
conditions,
 
reciprocity
 
mechanisms
 
and
 
governance
 
hooks
 
can
 
be
 
written
 
into
 
licence
 
and
 
service
 
terms
 
without
 
departing
 
from
 
established
 
contracting
 
practice.
 
Licences
 
are
 
treated
 
as
 
one
 
of
 
the
 
few
 
points
 
in
 
the
 
value
 
chain
 
where
 
detailed
 
conditions
 
are
 
already
 
negotiated
 
and
 
where
 
distributive
 
and
 
procedural
 
commitments
 
can
 
be
 
embedded
 
at
 
scale.
 
The
 
“licensing
 
layer”
 
is
 
used
 
broadly,
 
covering
 
standalone
 
IP
 
licences
 
and
 
licence-like
 
clauses
 
in
 
MSAs,
 
cloud
 
agreements
 
and
 
subscription
 
terms;
 
the
 
relevant
 
actor
 
may
 
be
 
a
 
developer,
 
platform
 
operator,
 
client
 
or
 
public
 
procurer.
 
The
 
paper
 
proceeds
 
as
 
follows.
 
Section
 
2
 
examines
 
systemic
 
effects
 
of
 
open-source
 
and
 
Creative
 
Commons
 
licensing.
 
Section
 
3
 
presents
 
short
 
scenarios
 
for
 
the
 
six
 
Commons
 
logics.
 
Section
 
4
 
explains
 
why
 
the
 
licensing
 
layer
 
is
 
a
 
distinct
 
intervention
 
point.
 
Section
 
5
 
clarifies
 
the
 
digital-commons
 
lineage.
 
Section
 
6
 
outlines
 
limits
 
and
 
scope.
 
Section
 
7
 
concludes.
 
2.
 
Systemic
 
Impacts
 
of
 
Licensing:
 
The
 
Cases
 
of
 
Open
 
Source
 
and
 
Creative
 
Commons
 
Before
 
turning
 
to
 
new
 
scenarios,
 
it
 
is
 
useful
 
to
 
consider
 
licensing
 
schemes
 
that
 
have
 
already
 
reshaped
 
societal
 
impacts
 
at
 
scale.
 
Two
 
families
 
are
 
particularly
 
important:
 
Creative
 
Commons
 
(CC)
 
licences
 
for
 
content
 
and
 
data,
 
and
 
open-source
 
software
 
licences
 
for
 
code
 
and,
 
increasingly,
 
model
 
weights.
 
Together,
 
they
 
still
 
provide
 
most
 
of
 
the
 
practical
 
“off-the-shelf”
 
options
 
available
 
to
 
AI
 
developers
 
who
 
wish
 
to
 
orient
 
their
 
systems
 
towards
 
broader
 
societal
 
benefit.
 
Creative
 
Commons
 
licences
 
were
 
introduced
 
in
 
the
 
early
 
2000s
 
to
 
give
 
rightsholders
 
standardised
 
ways
 
to
 
pre-authorise
 
use,
 
adaptation
 
and
 
redistribution
 
of
 
their
 
works
 
within
 
a
 
bounded
 
set
 
of
 
conditions
 
(Creative
 
Commons,
 
n.d.;
 
Dusollier,
 
2006).
 
A
 
CC
 
licence
 
asserts
 
copyright
 
and
 
then
 
waives
 
selected
 
exclusive
 
rights
 
through
 
boilerplate
 
permissions.
 
Their
 
systemic
 
effects
 
are
 
clearest
 
in
 
open
 
education
 
and
 
open
 
access.
 
Prior
 
to
 
CC,
 
reuse
 
of
 
teaching
 
materials
 
and
 
scholarly
 
outputs
 
imposed
 
high
 
transaction
 
costs
 
(Butcher,
 
2011).
 
Institutions
 
and
 
funders
 
had
 
to
 
negotiate
 
bespoke
 
permissions
 
or
 
rely
 
on
 
narrow
 
exceptions.
 
CC
 
licences
 
made
 
it
 
possible
 
for
 
institutions
 
and
 
funders
 
to
 
adopt
 
simple
 
rules
 
such
 
as
 
“all
 
materials
 
from
 
this
 
programme
 
must
 
be
 
released
 
under
 
CC
 
BY”.
 
This
 
supported
 
the
 
growth
 
of
 
open
 
educational
 
resource
 
repositories,
 
collaborative
 
textbooks
 
and
 
open-access
 
journals
 
that
 
rely
 
on
 
CC
 
BY
 
or
 
CC0
 
for
 
legal
 
interoperability
 
and
 
large-scale
 
text-and-data
 
mining
 
(Butcher,
 
2011;
 
Creative
 
Commons,
 
2012;
 
Margoni
 
&
 
Schirru,
 
2023).
 
In
 
these
 
domains,
 
licensing
 
shifted
 
the
 
default
 
from
 
closed
 
to
 
open
 
and
 
enabled
 
knowledge
 
commons
 
built
 
from
 
many
 
local
 
decisions.
 
Open-source
 
software
 
licences
 
have
 
a
 
parallel
 
history
 
on
 
the
 
code
 
side.
 
Licences
 
such
 
as
 
GPL,
 
LGPL,
 
MIT,
 
Apache
 
2.0
 
and
 
BSD
 
define
 
standardised
 
conditions
 
under
 
which
 
source
 
code
 
may
 
be
 
used,
 
modified
 
and
 
redistributed,
 
with
 
differing
 
approaches
 
to
 
reciprocity
 
and
 
patent
 
rights
 
(Rosen,
 
2004;
 
von
 
Hippel
 
&
 
von
 
Krogh,
 
2003).
 
They
 
have
 
enabled
 
distributed
 
development
 
models,
 
lowered
 
barriers
 
to
 
entry
 
and
 
created
 
shared
 
technical
 
infrastructures
 
on
 
which
 
both
 
commercial
 
and
 
non-commercial
 
actors
 
build
 
(Benkler,
 
2006).
 
In
 
AI,
 
these
 
licences
 
now
 
govern
 
libraries,
 
training
 
code
 
and
 
many
 
released
 
model
 
weights.
 
When
 
developers
 
publish
 
tooling
 
or
 
models
 
under
 
permissive
 
or
 
copyleft
 
terms,
 
they
 
turn
 
them
 
into
 
infrastructural
 
components
 
that
 
others
 
can
 
audit,
 
adapt
 
and
 
integrate
 
without
 
negotiation.
 
This
 
supports
 
open-model
 
ecosystems
 
in
 
which
 
more
 
actors
 
can
 
fine-tune,
 
compose
 
and
 
redeploy
 
systems.
 
 
2
 


--- PAGE 3 ---

 
These
 
licensing
 
choices
 
already
 
have
 
systemic
 
effects.
 
They
 
reduce
 
legal
 
and
 
transactional
 
friction
 
for
 
reusing
 
models,
 
code
 
and
 
corpora,
 
making
 
it
 
feasible
 
for
 
smaller
 
actors—start-ups,
 
academic
 
groups,
 
civil-society
 
organisations—to
 
develop
 
systems
 
without
 
bespoke
 
agreements.
 
They
 
support
 
decentralised
 
AI
 
marketplaces
 
and
 
strengthen
 
expectations
 
of
 
transparency
 
and
 
auditability.
 
For
 
the
 
purposes
 
of
 
this
 
paper,
 
the
 
combined
 
CC
 
and
 
open-source
 
landscape
 
serves
 
as
 
a
 
calibration
 
point.
 
It
 
shows
 
that
 
standardised
 
licence
 
families
 
can
 
materially
 
change
 
patterns
 
of
 
access,
 
reuse,
 
collaboration
 
and
 
competition
 
without
 
new
 
statutes
 
or
 
technical
 
primitives.
 
At
 
the
 
same
 
time,
 
these
 
instruments
 
remain
 
geared
 
towards
 
the
 
open
 
sharing
 
of
 
upstream
 
artefacts—code,
 
models,
 
datasets
 
and
 
documentation.
 
They
 
offer
 
limited
 
leverage
 
over
 
value
 
distribution,
 
impact
 
monitoring
 
or
 
ongoing
 
oversight.
 
In
 
practice,
 
they
 
reshape
 
who
 
can
 
build
 
and
 
adapt
 
systems,
 
but
 
leave
 
largely
 
untouched
 
who
 
captures
 
value,
 
how
 
impacts
 
are
 
monitored
 
and
 
who
 
has
 
standing
 
in
 
ongoing
 
oversight.
 
These
 
are
 
the
 
dimensions
 
that
 
the
 
six
 
Commons
 
logics
 
introduced
 
in
 
Section
 
3
 
are
 
designed
 
to
 
engage:
 
value
 
distribution,
 
transparency
 
in
 
use,
 
ecological
 
performance,
 
access
 
conditions,
 
reciprocity
 
along
 
contribution
 
chains
 
and
 
governance
 
structures
 
that
 
extend
 
beyond
 
individual
 
contracts.
 
3.
 
The
 
New
 
Design
 
Space:
 
Licensing
 
Logics
 
for
 
AI
 
The
 
six
 
Commons
 
logics—Value,
 
Transparency,
 
Sustainability,
 
Access,
 
Reciprocity
 
and
 
Governance—outline
 
a
 
design
 
space
 
for
 
impact-oriented
 
AI
 
licensing.
 
Each
 
asks
 
what
 
can
 
be
 
done
 
at
 
the
 
licensing
 
layer
 
given
 
existing
 
power
 
geometries
 
and
 
contractual
 
practice.
 
“Commons”
 
is
 
used
 
in
 
the
 
digital-commons
 
sense:
 
families
 
of
 
standardised
 
licence
 
or
 
service-agreement
 
profiles
 
whose
 
repeated
 
use
 
can
 
build
 
shared
 
resource
 
layers.
 
These
 
logics
 
extend
 
that
 
intuition
 
beyond
 
upstream
 
artefacts.
 
They
 
target
 
downstream
 
layers
 
where
 
access,
 
routing,
 
distribution
 
and
 
oversight
 
are
 
decided
 
and
 
where
 
compatible
 
contracts
 
could,
 
over
 
time,
 
accumulate
 
into
 
shared
 
infrastructures.
 
Each
 
designates
 
a
 
dimension
 
of
 
AI’s
 
systemic
 
footprint
 
where
 
many
 
individual
 
contracts
 
could
 
build
 
a
 
shared
 
resource
 
base.
 
A
 
Value
 
Commons
 
channels
 
portions
 
of
 
automation
 
gains
 
into
 
shared
 
funds
 
and
 
infrastructures.
 
A
 
Transparency
 
Commons
 
accumulates
 
reusable
 
documentation
 
and
 
evaluations.
 
A
 
Sustainability
 
Commons
 
gathers
 
ecological
 
accounting
 
and
 
constraints.
 
An
 
Access
 
Commons
 
supports
 
shared
 
infrastructures
 
and
 
conditions
 
of
 
meaningful
 
access.
 
A
 
Reciprocity
 
Commons
 
encodes
 
patterns
 
for
 
recognising
 
contributions
 
along
 
the
 
AI
 
value
 
chain.
 
A
 
Governance
 
Commons
 
explores
 
how
 
licensing
 
terms
 
might
 
create
 
durable
 
multi-stakeholder
 
oversight
 
above
 
individual
 
contracts.
 
These
 
logics
 
can
 
be
 
read
 
as
 
a
 
second
 
generation
 
of
 
digital-commons
 
design.
 
Creative
 
Commons
 
and
 
open-source
 
licences
 
shifted
 
the
 
default
 
for
 
upstream
 
artefacts
 
from
 
closed
 
to
 
reusable
 
but
 
left
 
access
 
to
 
compute,
 
deployment
 
infrastructures
 
and
 
value
 
flows
 
to
 
proprietary
 
arrangements.
 
The
 
proposed
 
Commons
 
logics
 
apply
 
the
 
same
 
design
 
intuition
 
downstream:
 
licences
 
and
 
service
 
agreements
 
become
 
places
 
where
 
conditions
 
of
 
access,
 
distribution
 
and
 
oversight
 
can
 
be
 
standardised
 
and
 
allowed
 
to
 
accumulate.
 
This
 
section
 
introduces
 
the
 
six
 
logics
 
through
 
short
 
hypothetical
 
examples.
 
The
 
aim
 
is
 
to
 
show
 
how
 
clause
 
patterns
 
could
 
function
 
in
 
recognisable
 
deployments
 
and
 
why
 
actors
 
might
 
adopt
 
them.
 
The
 
scenarios
 
illustrate
 
reusable
 
patterns
 
and
 
adoption
 
pathways,
 
not
 
bespoke
 
contractual
 
proposals.
 
 
3
 


--- PAGE 4 ---

 
3.1.
 
Value
 
Commons:
 
Sharing
 
Automation
 
Gains
 
The
 
Value
 
Commons
 
logic
 
targets
 
the
 
distribution
 
of
 
economic
 
gains
 
from
 
AI-enabled
 
automation.
 
It
 
asks
 
whether
 
licence
 
terms
 
can
 
help
 
channel
 
part
 
of
 
those
 
gains
 
towards
 
workers,
 
communities
 
or
 
shared
 
infrastructures
 
that,
 
under
 
conventional
 
licensing,
 
would
 
be
 
excluded
 
from
 
meaningful
 
participation
 
in
 
the
 
productivity
 
gains
 
their
 
work,
 
data
 
and
 
environments
 
help
 
generate.
 
The
 
focus
 
on
 
the
 
licensing
 
layer
 
is
 
deliberate.
 
The
 
licence
 
sits
 
at
 
the
 
boundary
 
between
 
providers
 
and
 
deployers.
 
It
 
is
 
routinely
 
renegotiated
 
in
 
procurement.
 
It
 
can
 
be
 
standardised
 
and
 
reused
 
across
 
contracts.
 
It
 
travels
 
with
 
the
 
system
 
as
 
that
 
system
 
is
 
integrated
 
into
 
wider
 
processes.
 
It
 
is
 
therefore
 
one
 
of
 
the
 
relatively
 
rare
 
points
 
in
 
the
 
lifecycle
 
where
 
powerful
 
actors
 
come
 
together
 
to
 
define
 
conditions
 
of
 
use
 
and
 
where
 
distributive
 
obligations
 
can
 
be
 
embedded
 
in
 
a
 
scalable
 
and
 
legally
 
enforceable
 
way.
 
The
 
following
 
scenarios
 
illustrate
 
different
 
ways
 
in
 
which
 
Value
 
Commons
 
clauses
 
could
 
be
 
formulated.
 
Example
 
3.1.1:
 
Large
 
Consultancy
 
and
 
Infrastructure
 
Client
 
A
 
global
 
consultancy
 
firm
 
secures
 
a
 
multi-year
 
modernisation
 
contract
 
with
 
a
 
major
 
European
 
infrastructure
 
provider.
 
The
 
aim
 
is
 
to
 
automate
 
large
 
parts
 
of
 
the
 
client’s
 
software
 
development
 
and
 
maintenance
 
pipeline.
 
Historically,
 
upgrades
 
of
 
this
 
kind
 
required
 
several
 
hundred
 
person-years
 
of
 
work
 
across
 
internal
 
teams
 
and
 
external
 
vendors.
 
With
 
the
 
new
 
AI-based
 
toolchain,
 
a
 
small
 
human
 
team
 
orchestrating
 
a
 
swarm
 
of
 
agents
 
can
 
deliver
 
comparable
 
change
 
with
 
an
 
order-of-magnitude
 
reduction
 
in
 
effort
 
and
 
calendar
 
time.
 
Under
 
a
 
Value
 
Commons
 
logic,
 
the
 
master
 
licence
 
and
 
services
 
agreement
 
does
 
not
 
treat
 
this
 
efficiency
 
gain
 
as
 
a
 
purely
 
bilateral
 
matter.
 
The
 
parties
 
adopt
 
a
 
Value
 
Commons
 
licence
 
profile
 
in
 
which
 
a
 
portion
 
of
 
documented
 
cost
 
savings
 
is
 
contractually
 
channelled
 
into
 
a
 
“transition
 
and
 
innovation
 
fund”
 
for
 
affected
 
staff
 
across
 
both
 
organisations.
 
Above
 
an
 
agreed
 
baseline
 
of
 
historical
 
spend,
 
a
 
fixed
 
percentage
 
of
 
annual
 
savings
 
on
 
development
 
and
 
maintenance
 
is
 
paid
 
into
 
the
 
fund
 
for
 
the
 
duration
 
of
 
the
 
contract.
 
The
 
licence
 
profile
 
defines
 
eligible
 
uses
 
of
 
the
 
fund—retraining
 
into
 
higher-skill
 
roles,
 
internal
 
mobility
 
programmes,
 
early-retirement
 
packages
 
and
 
worker-led
 
innovation
 
projects
 
that
 
explore
 
new
 
uses
 
of
 
the
 
AI
 
tooling.
 
Governance
 
provisions
 
require
 
that
 
representatives
 
of
 
affected
 
staff
 
sit
 
on
 
the
 
fund’s
 
steering
 
group
 
alongside
 
management
 
from
 
both
 
organisations,
 
and
 
that
 
annual
 
summaries
 
of
 
contributions
 
and
 
disbursements
 
are
 
made
 
available
 
to
 
staff
 
and,
 
where
 
appropriate,
 
regulators
 
or
 
works
 
councils.
 
The
 
consultancy
 
accepts
 
this
 
structure
 
because
 
it
 
stabilises
 
industrial
 
relations,
 
reduces
 
the
 
risk
 
of
 
industrial
 
action
 
and
 
strengthens
 
its
 
reputation
 
for
 
“responsible
 
automation”,
 
which
 
is
 
valuable
 
in
 
future
 
bids.
 
The
 
client
 
accepts
 
it
 
because
 
the
 
fund
 
lowers
 
internal
 
resistance
 
to
 
the
 
AI
 
programme
 
and
 
provides
 
a
 
visible,
 
auditable
 
response
 
to
 
concerns
 
about
 
job
 
loss.
 
The
 
Value
 
Commons
 
profile
 
thus
 
shifts
 
part
 
of
 
the
 
automation
 
surplus
 
into
 
a
 
shared
 
resource,
 
using
 
the
 
licensing
 
layer
 
that
 
already
 
shapes
 
the
 
commercial
 
relationship.
 
 
4
 


--- PAGE 5 ---

 
Example
 
3.1.2:
 
A
 
Foundational
 
AGI
 
Ecosystem
 
for
 
Poverty
 
Reduction
 
A
 
research
 
collective
 
develops
 
a
 
family
 
of
 
large-scale
 
language
 
and
 
reasoning
 
models
 
based
 
on
 
a
 
novel
 
cognitive
 
architecture.
 
The
 
project
 
is
 
grounded
 
in
 
long-standing
 
work
 
on
 
collective
 
intelligence
 
and
 
aims
 
explicitly
 
at
 
general-purpose
 
capabilities,
 
not
 
only
 
narrow
 
task
 
performance.
 
The
 
community
 
believes
 
that,
 
on
 
this
 
trajectory,
 
their
 
models
 
have
 
a
 
realistic
 
chance
 
of
 
becoming
 
a
 
foundational
 
layer
 
for
 
future
 
AI
 
systems,
 
including
 
major
 
enterprise
 
deployments.
 
The
 
code
 
and
 
model
 
weights
 
are
 
released
 
under
 
permissive
 
open-source
 
licences.
 
Governance
 
is
 
decentralised,
 
with
 
decisions
 
taken
 
through
 
a
 
foundation
 
and
 
working
 
groups
 
drawn
 
from
 
the
 
scientific
 
community.
 
A
 
market
 
analysis
 
shows
 
that
 
most
 
current
 
users
 
value
 
the
 
project’s
 
mission
 
and
 
ethos.
 
In
 
practice,
 
however,
 
most
 
use
 
cases
 
are
 
still
 
routine
 
productivity
 
tasks
 
in
 
existing
 
jobs:
 
drafting
 
emails,
 
generating
 
social
 
media
 
posts,
 
writing
 
code
 
snippets,
 
preparing
 
presentations.
 
The
 
productivity
 
gains
 
remain
 
largely
 
inside
 
existing
 
corporate
 
and
 
platform
 
structures.
 
Community
 
members
 
start
 
to
 
ask
 
whether,
 
by
 
making
 
the
 
models
 
open
 
and
 
collectively
 
governed,
 
they
 
have
 
already
 
done
 
all
 
they
 
can.
 
The
 
gains
 
from
 
everyday
 
use
 
flow
 
to
 
clients
 
and
 
employers.
 
The
 
project
 
itself
 
struggles
 
to
 
fund
 
ongoing
 
research,
 
evaluation
 
and
 
hosting
 
at
 
the
 
scale
 
required
 
for
 
advancing
 
this
 
alternative
 
AGI
 
trajectory.
 
A
 
line
 
of
 
higher-tier
 
paid
 
services
 
emerges—managed
 
hosting,
 
enterprise
 
support,
 
bespoke
 
fine-tunes
 
for
 
large
 
organisations—and
 
some
 
contributors
 
worry
 
that
 
the
 
project
 
is
 
drifting
 
towards
 
a
 
standard
 
commercial
 
profile.
 
Under
 
a
 
Value
 
Commons
 
logic,
 
the
 
community
 
decides
 
to
 
use
 
licensing
 
to
 
hard-wire
 
a
 
visible
 
division
 
of
 
cashflows
 
that
 
matches
 
its
 
scientific
 
ambitions.
 
The
 
core
 
models
 
remain
 
free
 
and
 
open
 
for
 
individual
 
and
 
non-profit
 
use
 
under
 
existing
 
open-source
 
terms.
 
Commercial
 
customers
 
who
 
take
 
up
 
higher-tier
 
products
 
and
 
services
 
do
 
so
 
under
 
a
 
separate
 
Value
 
Commons
 
commercial
 
licence.
 
That
 
licence
 
includes
 
a
 
value-sharing
 
clause:
 
a
 
fixed
 
percentage
 
of
 
all
 
sales
 
revenue
 
from
 
these
 
offerings
 
is
 
automatically
 
redirected
 
into
 
a
 
global
 
basic-income
 
scheme
 
for
 
economically
 
vulnerable
 
populations.
 
The
 
project
 
frames
 
this
 
scheme
 
as
 
a
 
concrete
 
contribution
 
towards
 
Sustainable
 
Development
 
Goal
 
1
 
on
 
poverty
 
eradication
 
within
 
the
 
current
 
decade.
 
The
 
licence
 
specifies
 
the
 
governance
 
structure
 
of
 
the
 
scheme,
 
the
 
payment
 
mechanisms
 
and
 
the
 
transparency
 
requirements.
 
Allocation
 
decisions
 
are
 
taken
 
by
 
a
 
dedicated
 
entity
 
that
 
includes
 
representatives
 
of
 
affected
 
communities,
 
development
 
economists
 
and
 
members
 
of
 
the
 
model
 
community.
 
Local
 
partners
 
administer
 
payments
 
in
 
selected
 
regions,
 
with
 
a
 
portfolio
 
that
 
expands
 
as
 
revenues
 
grow.
 
Regular,
 
independently
 
audited
 
impact
 
reports
 
are
 
published
 
and
 
linked
 
from
 
the
 
project’s
 
main
 
site.
 
As
 
the
 
models
 
improve
 
and
 
begin
 
to
 
anchor
 
enterprise-scale
 
deployments,
 
the
 
Value
 
Commons
 
profile
 
becomes
 
part
 
of
 
their
 
identity.
 
Downstream
 
users
 
know
 
that
 
when
 
they
 
deploy
 
this
 
family
 
of
 
models
 
to
 
automate
 
document
 
processing,
 
customer
 
service
 
or
 
software
 
development,
 
a
 
defined
 
share
 
of
 
the
 
resulting
 
revenue
 
flows,
 
by
 
contract,
 
into
 
basic-income
 
streams
 
for
 
people
 
whose
 
livelihoods
 
do
 
not
 
otherwise
 
feature
 
in
 
the
 
AI
 
value
 
chain.
 
For
 
organisations,
 
this
 
becomes
 
part
 
of
 
the
 
value
 
proposition:
 
by
 
choosing
 
this
 
model
 
family
 
over
 
technically
 
similar
 
alternatives,
 
they
 
back
 
an
 
AGI
 
trajectory
 
that
 
is
 
bound
 
to
 
a
 
concrete,
 
traceable
 
redistribution
 
mechanism.
 
The
 
combination
 
of
 
scientific
 
ambition
 
and
 
explicit
 
value-sharing
 
attracts
 
attention
 
from
 
funders,
 
policymakers
 
and
 
the
 
wider
 
public.
 
The
 
project
 
gains
 
visibility
 
as
 
a
 
serious
 
technical
 
contender
 
that
 
links
 
its
 
cognitive
 
architecture
 
to
 
a
 
global
 
Value
 
Commons
 
commitment.
 
As
 
adoption
 
spreads,
 
the
 
volume
 
of
 
value
 
flowing
 
through
 
the
 
licence
 
clauses
 
grows.
 
The
 
model
 
family
 
does
 
not
 
on
 
its
 
own
 
solve
 
global
 
poverty.
 
It
 
does,
 
however,
 
demonstrate
 
that
 
the
 
foundational
 
layers
 
of
 
an
 
advanced
 
AI
 
 
5
 


--- PAGE 6 ---

 
ecosystem
 
can
 
be
 
coupled,
 
through
 
licensing,
 
to
 
systematic
 
streams
 
of
 
support
 
for
 
those
 
who
 
would
 
otherwise
 
be
 
left
 
outside
 
the
 
gains
 
of
 
automation.
 
Example
 
3.1.3:
 
AI-Generated
 
Music
 
on
 
a
 
Streaming
 
Platform
 
A
 
global
 
music
 
streaming
 
platform
 
licenses
 
catalogues
 
from
 
record
 
labels,
 
independent
 
artists
 
and
 
collecting
 
societies.
 
It
 
also
 
begins
 
to
 
integrate
 
AI-generated
 
music.
 
Several
 
technology
 
vendors
 
offer
 
generative
 
music
 
engines
 
and
 
pre-composed
 
AI
 
tracks
 
under
 
standard
 
licensing
 
deals.
 
The
 
platform
 
tests
 
these
 
tracks
 
in
 
background
 
playlists,
 
mood
 
channels
 
and
 
functional
 
music
 
(focus,
 
sleep,
 
retail
 
environments).
 
Listener
 
data
 
show
 
that
 
AI-generated
 
music
 
performs
 
well
 
in
 
many
 
of
 
these
 
contexts.
 
Under
 
the
 
conventional
 
model,
 
revenues
 
are
 
pooled
 
and
 
distributed
 
to
 
rights-holders
 
according
 
to
 
existing
 
licensing
 
agreements.
 
For
 
human
 
artists
 
this
 
involves
 
the
 
familiar
 
complex
 
of
 
label
 
contracts,
 
performance
 
rights
 
organisations
 
and
 
direct
 
deals.
 
AI-generated
 
catalogues
 
are
 
treated
 
in
 
the
 
same
 
way
 
as
 
any
 
other
 
rights
 
catalogue:
 
the
 
platform
 
pays
 
the
 
AI
 
vendors
 
their
 
negotiated
 
share
 
and
 
retains
 
the
 
rest.
 
As
 
the
 
volume
 
of
 
AI
 
music
 
grows,
 
human
 
artists
 
begin
 
to
 
worry
 
that
 
their
 
share
 
of
 
total
 
streams,
 
and
 
thus
 
of
 
total
 
revenue,
 
will
 
be
 
eroded
 
by
 
catalogues
 
that
 
involve
 
no
 
human
 
musicians
 
at
 
all.
 
Under
 
a
 
Value
 
Commons
 
logic,
 
the
 
platform
 
and
 
AI
 
vendors
 
decide
 
to
 
structure
 
AI-generated
 
catalogues
 
differently.
 
Human-made
 
music
 
continues
 
to
 
be
 
licensed
 
and
 
remunerated
 
under
 
the
 
existing
 
arrangements.
 
AI-generated
 
tracks,
 
by
 
contrast,
 
must
 
be
 
delivered
 
under
 
a
 
“Value
 
Commons
 
for
 
Music”
 
licence
 
profile
 
as
 
a
 
condition
 
of
 
distribution
 
on
 
the
 
platform.
 
This
 
profile
 
sets
 
the
 
commercial
 
terms
 
between
 
platform
 
and
 
AI
 
vendors,
 
but
 
also
 
includes
 
a
 
Value
 
Commons
 
clause.
 
The
 
clause
 
stipulates
 
that
 
a
 
fixed
 
percentage
 
of
 
all
 
net
 
revenues
 
attributable
 
to
 
AI-generated
 
tracks
 
on
 
the
 
platform
 
is
 
paid
 
into
 
a
 
dedicated
 
“human
 
artists’
 
treasury”.
 
The
 
licence
 
profile
 
defines
 
how
 
the
 
treasury
 
is
 
governed
 
and
 
distributed.
 
An
 
independent
 
foundation,
 
with
 
a
 
governing
 
board
 
that
 
includes
 
representatives
 
of
 
artists’
 
unions,
 
independent
 
musicians
 
and
 
youth
 
music
 
organisations,
 
administers
 
the
 
funds.
 
The
 
distribution
 
formula
 
gives
 
a
 
baseline
 
share
 
to
 
all
 
registered
 
human
 
artists
 
on
 
the
 
platform
 
and
 
an
 
increased
 
weighting
 
for
 
stipends
 
and
 
grants
 
to
 
young
 
and
 
emerging
 
artists.
 
Part
 
of
 
the
 
treasury
 
supports
 
mentorship
 
schemes,
 
recording
 
bursaries
 
and
 
touring
 
support
 
for
 
early-stage
 
musicians.
 
Transparency
 
requirements
 
are
 
built
 
into
 
the
 
licence
 
terms.
 
The
 
platform
 
must
 
publish,
 
at
 
regular
 
intervals,
 
statistics
 
on
 
total
 
streams
 
of
 
AI-generated
 
tracks,
 
gross
 
and
 
net
 
revenues
 
from
 
those
 
streams,
 
contributions
 
to
 
the
 
treasury
 
and
 
the
 
categories
 
of
 
disbursement.
 
Basic
 
audit
 
rights
 
allow
 
the
 
foundation,
 
or
 
an
 
agreed
 
auditor,
 
to
 
verify
 
that
 
revenue
 
attribution
 
and
 
contributions
 
follow
 
the
 
contract.
 
AI
 
vendors
 
accept
 
these
 
terms
 
because
 
access
 
to
 
the
 
platform’s
 
global
 
audience
 
is
 
essential
 
to
 
their
 
business,
 
and
 
because
 
association
 
with
 
the
 
Value
 
Commons
 
profile
 
supports
 
their
 
own
 
claims
 
of
 
“artist-friendly”
 
AI.
 
The
 
platform
 
adopts
 
this
 
structure
 
because
 
it
 
reduces
 
conflict
 
with
 
human
 
artists,
 
mitigates
 
reputational
 
risk
 
associated
 
with
 
AI-generated
 
music
 
displacing
 
human
 
livelihoods
 
and
 
differentiates
 
its
 
brand
 
from
 
competitors
 
that
 
treat
 
AI
 
catalogues
 
primarily
 
as
 
a
 
cost-saving
 
device.
 
For
 
listeners
 
and
 
enterprise
 
customers,
 
the
 
Value
 
Commons
 
profile
 
makes
 
the
 
trade-off
 
explicit:
 
using
 
AI-generated
 
music
 
in
 
playlists,
 
shops
 
or
 
apps
 
does
 
not
 
simply
 
undercut
 
human
 
musicians;
 
by
 
contract,
 
a
 
defined
 
share
 
of
 
that
 
revenue
 
flows
 
into
 
a
 
shared
 
treasury
 
that
 
supports
 
the
 
next
 
generation
 
of
 
human
 
artists.
 
3.2.
 
Transparency
 
Commons:
 
Standardised
 
Evidence
 
of
 
Behaviour
 
 
6
 


--- PAGE 7 ---

 
The
 
Transparency
 
Commons
 
logic
 
targets
 
the
 
visibility
 
of
 
how
 
AI
 
deployments
 
operate
 
in
 
practice.
 
It
 
asks
 
whether
 
licence
 
terms
 
can
 
require
 
deployers
 
to
 
generate
 
and
 
contribute
 
standardised
 
transparency
 
artefacts—documentation,
 
evaluations,
 
operational
 
metrics,
 
incident
 
reports,
 
distributional
 
statistics—to
 
shared
 
repositories
 
that
 
regulators,
 
affected
 
groups
 
and
 
researchers
 
can
 
access
 
under
 
appropriate
 
safeguards.
 
The
 
aim
 
is
 
to
 
ensure
 
that,
 
above
 
defined
 
thresholds
 
of
 
scale
 
and
 
risk,
 
there
 
is
 
a
 
minimally
 
adequate
 
and
 
reusable
 
record
 
of
 
what
 
deployments
 
are
 
doing,
 
where
 
they
 
are
 
used
 
and
 
how
 
they
 
fail.
 
Across
 
domains,
 
these
 
obligations
 
fall
 
into
 
a
 
small
 
set
 
of
 
recurring
 
building
 
blocks.
 
Documentation
 
duties
 
concern
 
design-time
 
artefacts
 
such
 
as
 
model
 
and
 
system
 
cards
 
that
 
describe
 
inputs,
 
intended
 
uses
 
and
 
known
 
limitations.
 
Evaluation
 
duties
 
concern
 
test
 
suites
 
and
 
performance
 
profiles
 
that
 
show
 
how
 
deployments
 
behave
 
under
 
defined
 
conditions,
 
often
 
with
 
basic
 
breakdowns
 
across
 
languages,
 
regions
 
or
 
groups.
 
Operational
 
metrics
 
duties
 
concern
 
aggregate
 
traces
 
of
 
how
 
systems
 
are
 
actually
 
used
 
once
 
live,
 
including
 
volumes,
 
distributions
 
and
 
key
 
outcomes.
 
Incident
 
duties
 
concern
 
the
 
logging
 
of
 
serious
 
harms
 
and
 
near
 
misses
 
in
 
a
 
structured
 
way.
 
Change-log
 
duties
 
concern
 
the
 
registration
 
of
 
significant
 
model,
 
data
 
and
 
policy
 
updates
 
over
 
time.
 
Access
 
duties
 
concern
 
who
 
can
 
see
 
which
 
artefacts,
 
under
 
what
 
conditions,
 
through
 
which
 
shared
 
hubs
 
or
 
registries.
 
A
 
concrete
 
Transparency
 
Commons
 
profile
 
combines
 
some
 
of
 
these
 
building
 
blocks
 
into
 
a
 
clause
 
pattern
 
that
 
can
 
be
 
attached
 
to
 
many
 
licences
 
in
 
a
 
domain,
 
rather
 
than
 
reinvented
 
in
 
each
 
contract.
 
The
 
following
 
scenarios
 
illustrate
 
how
 
such
 
profiles
 
could
 
function
 
in
 
domains
 
where
 
opacity
 
is
 
particularly
 
consequential.
 
Example
 
3.2.1:
 
Platform
 
Content-Moderation
 
AI
 
Large
 
social-media
 
platforms
 
rely
 
on
 
AI
 
systems
 
to
 
flag
 
hate
 
speech,
 
harassment
 
and
 
disinformation.
 
Some
 
models
 
are
 
built
 
in-house.
 
Others
 
are
 
licensed
 
from
 
specialist
 
vendors.
 
Choices
 
about
 
training
 
data,
 
thresholds
 
and
 
escalation
 
rules
 
sit
 
in
 
internal
 
systems
 
and
 
private
 
contracts.
 
Civil-society
 
groups,
 
users
 
and
 
regulators
 
mainly
 
see
 
outcomes
 
and
 
high-level
 
policy
 
pages.
 
Regulation
 
in
 
several
 
jurisdictions
 
now
 
demands
 
“appropriate
 
transparency”
 
for
 
recommender
 
and
 
moderation
 
systems.
 
These
 
rules
 
set
 
expectations,
 
yet
 
leave
 
wide
 
discretion
 
over
 
what
 
artefacts
 
platforms
 
produce,
 
in
 
which
 
format,
 
and
 
how
 
they
 
share
 
them.
 
Under
 
a
 
Transparency
 
Commons
 
logic,
 
regulators
 
and
 
platforms
 
use
 
the
 
licensing
 
layer
 
to
 
make
 
these
 
duties
 
concrete
 
and
 
reusable.
 
They
 
support
 
a
 
cross-platform
 
Moderation
 
Transparency
 
Hub
 
and
 
adopt
 
a
 
Transparency
 
Commons
 
licence
 
profile
 
for
 
high-volume
 
moderation
 
deployments.
 
Any
 
platform
 
that
 
wants
 
to
 
display
 
a
 
recognised
 
transparency
 
seal
 
commits
 
to
 
governing
 
its
 
moderation
 
AI
 
under
 
this
 
profile.
 
For
 
external
 
systems,
 
vendors
 
must
 
offer
 
a
 
Transparency
 
Commons
 
version
 
if
 
they
 
want
 
large
 
platform
 
contracts.
 
For
 
in-house
 
systems,
 
platforms
 
license
 
the
 
models
 
to
 
themselves
 
under
 
the
 
same
 
profile
 
and
 
publish
 
the
 
internal
 
obligations.
 
The
 
profile
 
leaves
 
commercial
 
terms
 
untouched.
 
It
 
adds
 
defined
 
transparency
 
duties
 
that
 
travel
 
with
 
the
 
model
 
wherever
 
it
 
is
 
deployed
 
on
 
these
 
terms.
 
Covered
 
moderation
 
deployments
 
must
 
maintain
 
a
 
standard
 
transparency
 
pack:
 
a
 
structured
 
description
 
of
 
the
 
model
 
and
 
its
 
role
 
in
 
the
 
moderation
 
stack;
 
summaries
 
of
 
training
 
and
 
evaluation
 
data
 
sources;
 
evaluations
 
and
 
red-team
 
results
 
with
 
basic
 
breakdowns
 
by
 
language
 
and
 
region;
 
operational
 
metrics
 
such
 
as
 
volumes
 
and
 
regional
 
patterns
 
of
 
flags,
 
appeal
 
and
 
reversal
 
rates;
 
and
 
notable
 
failure
 
modes
 
in
 
each
 
major
 
category
 
of
 
content.
 
Significant
 
incidents
 
in
 
which
 
moderation
 
failures
 
cause
 
material
 
harm
 
are
 
logged
 
with
 
short
 
explanatory
 
notes
 
and
 
linked
 
to
 
the
 
relevant
 
model
 
versions
 
in
 
a
 
change
 
log.
 
Above
 
agreed
 
thresholds
 
of
 
user
 
scale
 
or
 
content
 
volume,
 
richer
 
logs
 
and
 
more
 
frequent
 
reporting
 
become
 
mandatory.
 
 
7
 


--- PAGE 8 ---

 
These
 
artefacts
 
are
 
deposited
 
in
 
the
 
Moderation
 
Transparency
 
Hub
 
under
 
access
 
rules
 
built
 
into
 
the
 
profile.
 
Supervisory
 
authorities
 
and
 
accredited
 
auditors
 
see
 
detailed
 
material.
 
Civil-society
 
organisations
 
and
 
researchers
 
access
 
more
 
aggregated
 
views.
 
The
 
public
 
sees
 
comparative
 
dashboards
 
across
 
platforms
 
and
 
over
 
time.
 
This
 
access
 
regime
 
turns
 
the
 
artefacts
 
into
 
a
 
shared
 
resource
 
rather
 
than
 
private
 
compliance
 
reports.
 
Vendors
 
and
 
platforms
 
accept
 
the
 
profile
 
because
 
it
 
becomes
 
a
 
standard
 
route
 
to
 
regulatory
 
comfort
 
and
 
to
 
large-scale
 
deployment,
 
and
 
because
 
clause
 
patterns
 
can
 
be
 
reused
 
across
 
systems
 
and
 
jurisdictions.
 
The
 
politics
 
of
 
content
 
moderation
 
remain
 
contested,
 
yet
 
a
 
shared
 
evidential
 
base
 
appears
 
because
 
the
 
licence
 
terms
 
that
 
govern
 
access
 
to
 
moderation
 
models
 
require
 
platforms
 
and
 
vendors
 
to
 
generate,
 
structure
 
and
 
share
 
transparency
 
artefacts
 
in
 
a
 
consistent
 
way.
 
Example
 
3.2.2:
 
Scientific
 
Discovery
 
and
 
Drug-Design
 
AI
 
A
 
consortium
 
of
 
laboratories
 
develops
 
an
 
AI
 
platform
 
that
 
proposes
 
small-molecule
 
drug
 
candidates.
 
Pharmaceutical
 
firms,
 
biotech
 
start-ups
 
and
 
universities
 
license
 
the
 
platform
 
on
 
standard
 
commercial
 
and
 
discounted
 
terms.
 
The
 
system
 
screens
 
chemical
 
spaces,
 
suggests
 
modifications
 
and
 
helps
 
prioritise
 
compounds
 
for
 
pre-clinical
 
and
 
early
 
clinical
 
work.
 
Existing
 
regulation
 
already
 
requires
 
sponsors
 
to
 
document
 
development
 
pathways
 
for
 
individual
 
candidates,
 
but
 
it
 
does
 
not
 
produce
 
a
 
shared,
 
cross-project
 
record
 
of
 
how
 
AI
 
tools
 
are
 
used
 
or
 
where
 
they
 
repeatedly
 
fail.
 
Under
 
a
 
Transparency
 
Commons
 
logic,
 
the
 
consortium
 
and
 
major
 
funders
 
set
 
up
 
a
 
Drug
 
Discovery
 
Transparency
 
Registry
 
and
 
adopt
 
a
 
Transparency
 
Commons
 
licence
 
profile
 
for
 
the
 
platform.
 
Commercial
 
access
 
terms
 
remain
 
unchanged.
 
Any
 
organisation
 
that
 
licenses
 
the
 
platform
 
under
 
this
 
profile
 
agrees
 
that,
 
when
 
an
 
AI-suggested
 
compound
 
enters
 
pre-clinical
 
or
 
clinical
 
development,
 
it
 
will
 
generate
 
a
 
standard
 
transparency
 
pack
 
and
 
deposit
 
a
 
compressed
 
provenance
 
record
 
in
 
the
 
Registry.
 
The
 
record
 
notes,
 
in
 
abstracted
 
form,
 
the
 
model
 
version
 
used;
 
key
 
input
 
data
 
types;
 
the
 
main
 
AI-driven
 
design
 
steps;
 
points
 
where
 
human
 
experts
 
overrode
 
or
 
refined
 
proposals;
 
and
 
whether
 
the
 
candidate
 
was
 
progressed
 
or
 
abandoned
 
and
 
why.
 
Identifiers
 
and
 
masking
 
techniques
 
allow
 
patterns
 
to
 
be
 
studied
 
without
 
revealing
 
full
 
recipes
 
or
 
confidential
 
business
 
strategies.
 
The
 
Registry
 
is
 
governed
 
by
 
a
 
foundation
 
that
 
includes
 
the
 
consortium,
 
public
 
funders,
 
regulators
 
and
 
patient
 
representatives.
 
Drug
 
agencies
 
and
 
independent
 
reviewers
 
receive
 
confidential
 
access
 
to
 
detailed
 
records.
 
Academic
 
researchers
 
and
 
method
 
developers
 
can
 
query
 
aggregated
 
views
 
to
 
see
 
where
 
AI-supported
 
discovery
 
tends
 
to
 
succeed
 
or
 
fail
 
across
 
compound
 
classes,
 
indication
 
areas
 
and
 
model
 
versions.
 
Firms
 
accept
 
the
 
Transparency
 
Commons
 
profile
 
because
 
it
 
becomes
 
a
 
condition
 
of
 
participating
 
in
 
publicly
 
supported
 
discovery
 
programmes
 
and
 
of
 
receiving
 
certain
 
forms
 
of
 
de-risking
 
capital,
 
and
 
because
 
in
 
return
 
they
 
gain
 
access
 
to
 
an
 
otherwise
 
unavailable
 
pool
 
of
 
structured
 
negative
 
results
 
and
 
cross-project
 
benchmarks.
 
The
 
transparency
 
layer
 
exists
 
because
 
the
 
licence
 
that
 
governs
 
access
 
to
 
the
 
AI
 
platform
 
requires
 
users
 
to
 
leave
 
a
 
standardised
 
trace
 
once
 
candidates
 
move
 
beyond
 
the
 
laboratory.
 
Example
 
3.2.3:
 
AI-Supported
 
HR
 
Analytics
 
and
 
Pay
 
Equity
 
A
 
vendor
 
offers
 
an
 
AI-supported
 
HR
 
analytics
 
platform
 
to
 
large
 
employers.
 
The
 
system
 
ingests
 
payroll
 
data,
 
performance
 
reviews,
 
promotion
 
histories
 
and
 
training
 
records.
 
It
 
forecasts
 
turnover
 
risk,
 
highlights
 
“high
 
potentials”
 
and
 
proposes
 
salary
 
bands
 
and
 
bonus
 
pools.
 
Equalities
 
law
 
already
 
prohibits
 
discrimination
 
and,
 
in
 
some
 
jurisdictions,
 
requires
 
pay-gap
 
reporting.
 
These
 
duties
 
are
 
usually
 
implemented
 
through
 
bespoke
 
spreadsheets
 
and
 
one-off
 
audits.
 
There
 
is
 
no
 
shared,
 
cross-firm
 
structure
 
for
 
understanding
 
how
 
AI-assisted
 
decisions
 
relate
 
to
 
pay
 
and
 
progression
 
outcomes
 
over
 
time.
 
 
8
 


--- PAGE 9 ---

 
Under
 
a
 
Transparency
 
Commons
 
logic,
 
the
 
vendor
 
and
 
a
 
group
 
of
 
anchor
 
clients
 
agree
 
to
 
govern
 
the
 
platform
 
under
 
a
 
Transparency
 
Commons
 
licence
 
profile
 
for
 
HR
 
analytics.
 
Commercial
 
terms
 
remain
 
unchanged.
 
Employers
 
that
 
opt
 
into
 
this
 
profile
 
accept
 
additional
 
transparency
 
obligations
 
once
 
they
 
deploy
 
the
 
system
 
above
 
defined
 
thresholds
 
of
 
workforce
 
size
 
and
 
automation.
 
The
 
licence
 
requires
 
the
 
vendor
 
to
 
provide
 
a
 
clear,
 
structured
 
description
 
of
 
the
 
system
 
as
 
part
 
of
 
a
 
transparency
 
pack:
 
which
 
input
 
data
 
are
 
used,
 
how
 
performance
 
and
 
“potential”
 
scores
 
are
 
computed,
 
how
 
recommendations
 
for
 
pay
 
and
 
promotion
 
are
 
generated,
 
and
 
which
 
parameters
 
clients
 
can
 
tune.
 
Employers,
 
as
 
deployers,
 
commit
 
to
 
generate
 
aggregate
 
metrics
 
that
 
relate
 
AI-supported
 
recommendations
 
to
 
outcomes
 
at
 
regular
 
intervals.
 
They
 
produce
 
distributions
 
of
 
base
 
pay,
 
bonuses,
 
promotion
 
rates
 
and
 
performance
 
scores
 
by
 
gender,
 
age
 
cohort
 
and
 
other
 
legally
 
recognised
 
categories,
 
where
 
the
 
collection
 
and
 
use
 
of
 
such
 
data
 
for
 
equalities
 
monitoring
 
is
 
authorised,
 
broken
 
down
 
by
 
job
 
family
 
and
 
level.
 
The
 
profile
 
specifies
 
minimum
 
sample
 
sizes
 
and
 
anonymisation
 
rules
 
so
 
that
 
metrics
 
are
 
informative
 
without
 
revealing
 
individuals.
 
A
 
simple
 
change
 
log
 
records
 
significant
 
alterations
 
to
 
scoring
 
algorithms,
 
weightings
 
and
 
thresholds
 
and
 
links
 
them
 
to
 
subsequent
 
reporting
 
periods.
 
Where
 
internal
 
or
 
external
 
reviews
 
identify
 
serious
 
disparities
 
that
 
plausibly
 
relate
 
to
 
AI-supported
 
decisions,
 
the
 
employer
 
logs
 
an
 
incident
 
summary
 
and
 
a
 
short
 
account
 
of
 
remedial
 
steps.
 
These
 
documentation,
 
operational
 
metrics,
 
incident
 
and
 
change-log
 
duties
 
do
 
not
 
fix
 
pay
 
or
 
promotion
 
policies,
 
yet
 
they
 
create
 
a
 
consistent
 
view
 
of
 
how
 
AI-supported
 
recommendations
 
correlate
 
with
 
observed
 
outcomes
 
over
 
time.
 
Access
 
to
 
the
 
resulting
 
artefacts
 
is
 
defined
 
by
 
the
 
same
 
profile.
 
Works
 
councils,
 
equalities
 
officers
 
and
 
recognised
 
unions
 
receive
 
access
 
to
 
detailed
 
internal
 
dashboards
 
based
 
on
 
the
 
standard
 
metrics.
 
Sectoral
 
regulators
 
and
 
equalities
 
bodies
 
can
 
request
 
the
 
standard
 
package
 
under
 
confidentiality.
 
Investors
 
and
 
the
 
wider
 
public
 
may
 
see
 
high-level
 
indicators
 
in
 
sustainability
 
or
 
governance
 
reports,
 
presented
 
in
 
a
 
format
 
that
 
is
 
comparable
 
across
 
firms
 
using
 
the
 
profile.
 
Employers
 
accept
 
the
 
Transparency
 
Commons
 
profile
 
because
 
it
 
helps
 
them
 
evidence
 
compliance
 
with
 
equal-pay
 
and
 
non-discrimination
 
duties
 
and
 
gives
 
HR
 
and
 
legal
 
teams
 
a
 
clear
 
template
 
for
 
what
 
to
 
measure.
 
The
 
vendor
 
accepts
 
it
 
because
 
large
 
clients
 
begin
 
to
 
require
 
recognised
 
transparency
 
profiles
 
in
 
procurement
 
and
 
because
 
supporting
 
one
 
standard
 
is
 
easier
 
than
 
addressing
 
many
 
bespoke
 
requests.
 
The
 
licence
 
functions
 
as
 
a
 
cross-firm
 
implementation
 
device
 
for
 
existing
 
equalities
 
obligations,
 
in
 
a
 
form
 
that
 
can
 
be
 
reused
 
across
 
clients
 
and
 
jurisdictions.
 
The
 
regime
 
does
 
not
 
replace
 
equal-pay
 
statutes
 
or
 
collective
 
bargaining.
 
It
 
adds
 
a
 
reusable
 
evidential
 
layer
 
around
 
AI-supported
 
HR
 
decisions
 
that
 
exists
 
because
 
access
 
to
 
the
 
analytics
 
platform
 
is
 
conditioned
 
on
 
generating
 
and
 
sharing
 
salary
 
and
 
progression
 
metrics
 
in
 
a
 
structured,
 
comparable
 
way.
 
3.3.
 
Sustainability
 
Commons:
 
Ecological
 
Accounting
 
and
 
Routing
 
The
 
Sustainability
 
Commons
 
logic
 
targets
 
the
 
material
 
footprint
 
of
 
AI
 
deployments:
 
the
 
energy
 
they
 
consume,
 
the
 
emissions
 
they
 
drive,
 
the
 
hardware
 
they
 
run
 
on
 
and
 
the
 
infrastructures
 
that
 
host
 
them.
 
It
 
asks
 
whether
 
licence
 
terms
 
can
 
require
 
providers
 
and
 
deployers
 
to
 
measure,
 
disclose
 
and
 
improve
 
the
 
ecological
 
costs
 
of
 
AI
 
workloads,
 
and
 
whether
 
these
 
obligations
 
can
 
travel
 
with
 
models
 
and
 
services
 
as
 
they
 
are
 
adapted
 
and
 
redeployed
 
across
 
contexts.
 
The
 
focus
 
extends
 
beyond
 
raw
 
carbon
 
accounting
 
to
 
routing
 
workloads
 
towards
 
lower-impact
 
resources
 
and
 
building
 
shared
 
reference
 
datasets
 
on
 
AI-related
 
energy
 
use
 
and
 
emissions.
 
The
 
Sustainability
 
Commons
 
uses
 
the
 
licensing
 
layer
 
because
 
that
 
is
 
where
 
rights
 
to
 
run
 
large
 
workloads
 
are
 
granted,
 
capacity
 
is
 
reserved
 
and
 
service
 
levels
 
are
 
negotiated.
 
Licences
 
can
 
require
 
standardised
 
energy
 
and
 
emissions
 
reporting
 
on
 
a
 
shared
 
template,
 
with
 
clear
 
system
 
boundaries
 
and
 
basic
 
intensity
 
metrics
 
summarised
 
in
 
a
 
public
 
S
 
sheet.
 
They
 
can
 
extend
 
sustainability
 
duties
 
 
9
 


--- PAGE 10 ---

 
upstream
 
to
 
infrastructure
 
providers
 
and
 
downstream
 
to
 
commercial
 
products,
 
commit
 
deployments
 
to
 
simple
 
efficiency
 
and
 
reduction
 
targets,
 
and
 
switch
 
on
 
stronger
 
conditions
 
once
 
usage
 
or
 
revenue
 
crosses
 
agreed
 
thresholds.
 
Basic
 
metrics
 
and
 
lessons
 
learnt
 
feed
 
into
 
a
 
common
 
registry
 
that
 
supports
 
benchmarking,
 
procurement
 
and
 
oversight.
 
The
 
following
 
scenarios
 
explore
 
how
 
Sustainability
 
Commons
 
clauses
 
could
 
be
 
formulated
 
in
 
AI
 
deployments
 
that
 
rely
 
heavily
 
on
 
distributed
 
compute
 
and
 
data
 
centres.
 
Example
 
3.3.1:
 
A
 
Distributed
 
Compute
 
Network
 
with
 
Sustainability
 
Commons
 
Onboarding
 
A
 
decentralised
 
compute
 
network
 
allows
 
owners
 
of
 
servers,
 
GPUs
 
and
 
edge
 
devices
 
to
 
offer
 
spare
 
capacity
 
for
 
AI
 
workloads.
 
A
 
protocol
 
matches
 
compute
 
buyers
 
and
 
sellers
 
and
 
routes
 
tasks
 
across
 
a
 
global
 
pool
 
of
 
machines.
 
AI
 
developers
 
and
 
enterprises
 
license
 
access
 
to
 
the
 
network
 
as
 
a
 
service;
 
device
 
operators
 
sign
 
separate
 
participation
 
agreements.
 
Under
 
baseline
 
terms,
 
pricing
 
reflects
 
capacity,
 
latency
 
and
 
reliability.
 
Information
 
about
 
energy
 
sources
 
and
 
carbon
 
intensity
 
is
 
limited.
 
Jobs
 
chase
 
the
 
cheapest
 
or
 
fastest
 
nodes,
 
regardless
 
of
 
ecological
 
cost.
 
A
 
Sustainability
 
Commons
 
logic
 
treats
 
these
 
access
 
agreements
 
as
 
a
 
governance
 
lever.
 
The
 
network
 
operator
 
introduces
 
an
 
AIC-S
 
profile
 
for
 
the
 
network
 
and
 
for
 
node
 
operators
 
that
 
wish
 
to
 
participate.
 
Buyers
 
can
 
continue
 
under
 
baseline
 
terms,
 
or
 
opt
 
into
 
the
 
AIC-S-enabled
 
pool.
 
If
 
they
 
opt
 
in,
 
their
 
access
 
licence
 
includes
 
concrete
 
ecological
 
accounting
 
and
 
improvement
 
obligations.
 
The
 
operator,
 
in
 
turn,
 
commits
 
to
 
provide
 
the
 
data
 
and
 
controls
 
needed
 
to
 
honour
 
those
 
obligations.
 
On
 
the
 
supply
 
side,
 
nodes
 
that
 
seek
 
AIC-S
 
status
 
must
 
complete
 
a
 
standard
 
S
 
template
 
that
 
records
 
basic
 
energy
 
metadata—grid
 
region,
 
approximate
 
energy
 
mix
 
or
 
the
 
use
 
of
 
on-site
 
renewables,
 
hardware
 
type
 
and
 
typical
 
utilisation
 
ranges—and
 
accept
 
simple
 
metering
 
or
 
estimation
 
rules
 
for
 
power
 
use.
 
The
 
network
 
maps
 
these
 
declarations
 
into
 
a
 
small
 
set
 
of
 
standard
 
categories
 
and
 
publishes
 
an
 
S
 
sheet
 
for
 
the
 
network
 
that
 
summarises
 
the
 
footprint
 
and
 
boundary
 
choices.
 
On
 
the
 
demand
 
side,
 
AIC-S
 
workloads
 
agree
 
that
 
a
 
defined
 
fraction
 
of
 
their
 
jobs
 
will
 
run
 
on
 
nodes
 
in
 
preferred
 
categories
 
such
 
as
 
renewable-heavy
 
grids,
 
surplus-capacity
 
data
 
centres
 
or
 
clusters
 
that
 
meet
 
agreed
 
efficiency
 
benchmarks.
 
Above
 
a
 
usage
 
threshold,
 
the
 
licence
 
commits
 
the
 
network
 
to
 
tighten
 
routing
 
preferences
 
or
 
to
 
require
 
node
 
operators
 
in
 
the
 
AIC-S
 
pool
 
to
 
adopt
 
simple
 
efficiency
 
and
 
reduction
 
targets
 
over
 
a
 
multi-year
 
horizon.
 
Measurement
 
is
 
kept
 
deliberately
 
simple.
 
The
 
licence
 
refers
 
to
 
a
 
shared
 
formula
 
for
 
estimating
 
energy
 
use
 
per
 
job
 
based
 
on
 
hardware
 
type,
 
utilisation
 
and
 
runtime.
 
The
 
network
 
aggregates
 
these
 
data
 
and
 
provides
 
AIC-S
 
customers
 
with
 
periodic
 
reports:
 
total
 
compute,
 
estimated
 
emissions,
 
share
 
of
 
work
 
routed
 
to
 
preferred
 
categories
 
and
 
progress
 
against
 
declared
 
intensity
 
targets.
 
Core
 
metrics
 
are
 
deposited,
 
in
 
aggregated
 
form,
 
in
 
an
 
external
 
Sustainability
 
Commons
 
registry
 
that
 
supports
 
cross-network
 
benchmarking.
 
Because
 
the
 
same
 
AIC-S
 
profile
 
applies
 
across
 
buyers
 
and
 
operators,
 
ecological
 
clauses
 
do
 
not
 
need
 
to
 
be
 
renegotiated
 
in
 
each
 
bilateral
 
contract.
 
Example
 
3.3.2:
 
Hyperscale
 
Cloud
 
“Sustainability
 
Commons
 
–
 
Training”
 
Profile
 
for
 
Large
 
Models
 
A
 
major
 
cloud
 
provider
 
offers
 
specialised
 
GPU
 
clusters
 
for
 
training
 
large
 
models.
 
Access
 
to
 
these
 
clusters
 
is
 
governed
 
by
 
reserved-capacity
 
service
 
agreements
 
rather
 
than
 
pure
 
pay-as-you-go.
 
Training
 
jobs
 
above
 
a
 
defined
 
threshold
 
of
 
compute
 
or
 
spend
 
must
 
be
 
booked
 
under
 
named
 
service
 
profiles.
 
Under
 
a
 
Sustainability
 
Commons
 
logic,
 
the
 
provider
 
introduces
 
a
 
“Sustainability
 
Commons
 
–
 
Training”
 
profile
 
as
 
one
 
of
 
these
 
options.
 
 
10
 


--- PAGE 11 ---

 
The
 
Training
 
profile
 
leaves
 
core
 
commercial
 
terms
 
intact,
 
but
 
adds
 
ecological
 
accounting
 
and
 
improvement
 
duties
 
that
 
attach
 
to
 
each
 
covered
 
training
 
run.
 
Customers
 
who
 
opt
 
in
 
agree
 
that
 
large
 
training
 
jobs
 
will,
 
where
 
feasible,
 
be
 
scheduled
 
in
 
regions
 
that
 
meet
 
basic
 
criteria
 
on
 
energy
 
mix
 
and
 
efficiency,
 
unless
 
latency
 
or
 
data-localisation
 
requirements
 
make
 
this
 
impossible.
 
The
 
service
 
terms
 
commit
 
the
 
provider
 
to
 
publish
 
an
 
S
 
sheet
 
for
 
the
 
Training
 
profile
 
and
 
to
 
expose,
 
for
 
each
 
covered
 
run,
 
a
 
standardised
 
estimate
 
of
 
energy
 
use
 
and
 
associated
 
emissions,
 
based
 
on
 
hardware
 
type,
 
runtime
 
and
 
regional
 
grid
 
factors.
 
Above
 
a
 
higher
 
threshold
 
of
 
annual
 
Training-profile
 
usage
 
or
 
emissions,
 
the
 
profile
 
requires
 
the
 
customer
 
and
 
provider
 
to
 
adopt
 
simple
 
intensity
 
or
 
reduction
 
targets
 
for
 
future
 
runs
 
and
 
to
 
subject
 
the
 
reporting
 
process
 
to
 
periodic
 
independent
 
assurance.
 
For
 
runs
 
that
 
cross
 
defined
 
thresholds,
 
anonymised
 
training-run
 
metadata—model
 
size
 
bands,
 
total
 
compute,
 
estimated
 
energy
 
and
 
region—are
 
deposited
 
in
 
a
 
shared
 
Training
 
Footprint
 
Registry
 
maintained
 
by
 
an
 
independent
 
body.
 
That
 
Registry
 
forms
 
part
 
of
 
the
 
broader
 
Sustainability
 
Commons
 
registry,
 
and
 
supports
 
benchmarking
 
and
 
policy
 
analysis
 
across
 
firms
 
and
 
sectors.
 
Public
 
funders,
 
corporate
 
sustainability
 
programmes
 
and
 
some
 
regulators
 
begin
 
to
 
require
 
that
 
publicly
 
supported
 
or
 
high-risk
 
large-model
 
training
 
runs
 
use
 
a
 
recognised
 
Sustainability
 
Commons
 
profile
 
or
 
explain
 
why
 
they
 
do
 
not.
 
For
 
the
 
cloud
 
provider,
 
the
 
profile
 
becomes
 
a
 
standard
 
product
 
line
 
that
 
responds
 
to
 
these
 
demands
 
and
 
allows
 
ecological
 
accounting
 
to
 
be
 
handled
 
once
 
in
 
the
 
service
 
terms
 
rather
 
than
 
through
 
individual
 
side
 
letters.
 
For
 
customers,
 
it
 
offers
 
a
 
concrete,
 
auditable
 
way
 
to
 
back
 
“responsible
 
AI
 
training”
 
claims.
 
Example
 
3.3.3:
 
Logistics
 
Optimisation
 
SaaS
 
with
 
AIC-S
 
Routing
 
and
 
Reporting
 
A
 
software
 
vendor
 
licenses
 
an
 
AI
 
optimisation
 
platform
 
to
 
large
 
retailers
 
and
 
logistics
 
firms.
 
The
 
system
 
plans
 
delivery
 
routes,
 
allocates
 
loads
 
across
 
vehicles
 
and
 
depots,
 
and
 
balances
 
cost,
 
delivery
 
time
 
and
 
service
 
levels.
 
Enterprise
 
customers
 
contract
 
through
 
long-term
 
SaaS
 
agreements
 
with
 
usage-based
 
billing.
 
Under
 
standard
 
terms,
 
the
 
optimiser
 
is
 
free
 
to
 
choose
 
any
 
feasible
 
routing
 
that
 
minimises
 
monetary
 
cost
 
or
 
time.
 
Environmental
 
impact
 
remains
 
an
 
internal
 
matter
 
for
 
each
 
client.
 
Under
 
a
 
Sustainability
 
Commons
 
logic,
 
the
 
vendor
 
offers
 
an
 
alternative
 
“Sustainability
 
Commons
 
–
 
Logistics”
 
licence
 
profile
 
based
 
on
 
AIC-S.
 
Clients
 
who
 
choose
 
this
 
profile
 
keep
 
the
 
same
 
core
 
functionality
 
and
 
pricing
 
model,
 
but
 
accept
 
additional
 
ecological
 
accounting
 
and
 
routing
 
rules
 
once
 
optimisation
 
volumes
 
cross
 
defined
 
thresholds.
 
The
 
licence
 
requires
 
the
 
platform
 
to
 
estimate,
 
for
 
each
 
covered
 
optimisation
 
run,
 
energy
 
use
 
and
 
emissions
 
using
 
standard
 
factors
 
linked
 
to
 
vehicle
 
type,
 
fuel,
 
distance
 
and
 
load.
 
It
 
also
 
requires
 
the
 
optimiser
 
to
 
treat
 
emissions
 
as
 
a
 
constrained
 
objective:
 
where
 
two
 
routing
 
plans
 
fall
 
within
 
an
 
agreed
 
band
 
of
 
cost
 
and
 
delivery
 
time,
 
the
 
lower-emission
 
option
 
is
 
selected
 
by
 
default,
 
unless
 
the
 
client
 
explicitly
 
overrides
 
this
 
choice
 
and
 
records
 
a
 
short
 
explanation.
 
Each
 
client
 
maintains
 
an
 
S
 
sheet
 
that
 
summarises
 
system
 
boundaries,
 
estimation
 
methods
 
and
 
basic
 
intensity
 
metrics,
 
for
 
example
 
emissions
 
per
 
parcel
 
or
 
per
 
tonne-kilometre
 
in
 
covered
 
segments.
 
The
 
profile
 
mandates
 
that
 
anonymised,
 
aggregated
 
metrics—total
 
distance,
 
modal
 
split,
 
estimated
 
emissions
 
by
 
corridor
 
and
 
customer
 
segment,
 
progress
 
against
 
simple
 
intensity
 
targets—be
 
deposited
 
at
 
regular
 
intervals
 
into
 
the
 
Sustainability
 
Commons
 
registry
 
for
 
participating
 
firms.
 
Access
 
rules,
 
defined
 
in
 
the
 
same
 
profile,
 
grant
 
sectoral
 
regulators,
 
city
 
authorities
 
and
 
accredited
 
researchers
 
access
 
to
 
these
 
aggregates,
 
while
 
firms
 
retain
 
control
 
over
 
fine-grained
 
operational
 
data.
 
Public
 
procurement
 
frameworks
 
and
 
some
 
investors
 
begin
 
to
 
recognise
 
participation
 
in
 
such
 
AIC-S
 
profiles
 
as
 
evidence
 
of
 
responsible
 
logistics
 
practices.
 
 
11
 


--- PAGE 12 ---

 
For
 
clients,
 
the
 
profile
 
provides
 
a
 
ready-made
 
structure
 
for
 
reporting
 
and
 
for
 
modestly
 
constraining
 
the
 
environmental
 
impact
 
of
 
AI-optimised
 
operations,
 
with
 
a
 
built-in
 
expectation
 
of
 
gradual
 
improvement
 
over
 
time.
 
For
 
the
 
vendor,
 
it
 
is
 
a
 
reusable
 
clause
 
pattern
 
that
 
meets
 
converging
 
regulatory
 
and
 
customer
 
expectations
 
without
 
bespoke
 
side
 
agreements,
 
and
 
that
 
connects
 
the
 
platform
 
to
 
a
 
broader
 
Sustainability
 
Commons
 
in
 
which
 
footprint
 
data
 
and
 
improvement
 
trajectories
 
can
 
be
 
compared
 
across
 
firms
 
and
 
sectors.
 
3.4.
 
Access
 
Commons:
 
Conditions
 
of
 
Meaningful
 
Use
 
The
 
Access
 
Commons
 
logic
 
targets
 
who
 
can,
 
in
 
practice,
 
make
 
meaningful
 
use
 
of
 
advanced
 
AI
 
capabilities
 
and
 
on
 
what
 
terms.
 
Formal
 
openness
 
of
 
code
 
or
 
model
 
weights
 
does
 
not
 
by
 
itself
 
ensure
 
that
 
under-resourced
 
actors
 
can
 
deploy,
 
adapt
 
or
 
govern
 
these
 
systems.
 
Barriers
 
arise
 
from
 
infrastructure
 
costs,
 
expertise,
 
legal
 
risk
 
and
 
the
 
need
 
for
 
context-specific
 
support.
 
Access
 
Commons
 
clauses
 
ask
 
whether
 
licence
 
terms
 
can
 
carve
 
out
 
predictable
 
access
 
conditions
 
for
 
defined
 
groups:
 
public-interest
 
users,
 
research
 
institutions
 
in
 
low-resource
 
settings,
 
civil-society
 
organisations
 
or
 
small
 
firms
 
working
 
on
 
specific
 
problems.
 
Here
 
the
 
licensing
 
layer
 
is
 
where
 
price,
 
volume,
 
support
 
and
 
technical
 
modalities
 
of
 
access
 
are
 
negotiated.
 
Licences
 
can
 
specify
 
tiers
 
and
 
segments,
 
reserve
 
slices
 
of
 
capacity
 
for
 
particular
 
user
 
groups,
 
cap
 
prices
 
for
 
certain
 
categories
 
of
 
use
 
or
 
require
 
that
 
some
 
forms
 
of
 
access
 
be
 
channelled
 
through
 
shared
 
platforms
 
with
 
common
 
support
 
arrangements.
 
The
 
following
 
scenarios
 
illustrate
 
how
 
Access
 
Commons
 
profiles
 
might
 
work
 
in
 
AI-as-a-service,
 
marketplace
 
and
 
infrastructure
 
settings.
 
In
 
all
 
three
 
cases,
 
the
 
Access
 
Commons
 
profiles
 
do
 
not
 
replace
 
open-source
 
or
 
Creative
 
Commons
 
licences
 
on
 
upstream
 
artefacts.
 
They
 
sit
 
alongside
 
them,
 
extending
 
the
 
digital-commons
 
logic
 
from
 
reusable
 
works
 
of
 
authorship
 
to
 
the
 
contractual
 
conditions
 
under
 
which
 
advanced
 
AI
 
capabilities
 
and
 
compute
 
are
 
made
 
available.
 
Example
 
3.4.1:
 
Foundation-Model
 
API
 
with
 
a
 
Public-Interest
 
Tier
 
A
 
company
 
offers
 
large
 
language
 
and
 
vision
 
models
 
through
 
a
 
commercial
 
API.
 
Most
 
customers
 
are
 
firms
 
that
 
integrate
 
the
 
API
 
into
 
products,
 
internal
 
tooling
 
and
 
analytics.
 
The
 
standard
 
licence
 
sets
 
usage-based
 
prices,
 
support
 
levels
 
and
 
service
 
guarantees.
 
Public-interest
 
users—civil-society
 
organisations,
 
small
 
public
 
institutions,
 
research
 
groups
 
in
 
low-resource
 
settings—face
 
the
 
same
 
terms
 
and
 
often
 
cannot
 
afford
 
sustained
 
use.
 
Under
 
an
 
Access
 
Commons
 
logic,
 
the
 
provider
 
introduces
 
a
 
distinct
 
Access
 
Commons
 
profile
 
for
 
the
 
API.
 
Commercial
 
customers
 
keep
 
the
 
standard
 
licence.
 
Eligible
 
public-interest
 
users
 
can
 
instead
 
contract
 
under
 
the
 
Access
 
Commons
 
terms.
 
These
 
terms
 
reserve
 
a
 
defined
 
slice
 
of
 
total
 
capacity
 
for
 
the
 
Access
 
Commons
 
tier,
 
set
 
a
 
stable,
 
near-cost
 
price
 
band
 
for
 
a
 
clear
 
usage
 
envelope,
 
and
 
guarantee
 
basic
 
support
 
rather
 
than
 
“best-effort”
 
access.
 
Eligibility
 
rules
 
and
 
accreditation
 
are
 
defined
 
in
 
an
 
annex,
 
co-designed
 
with
 
public
 
funders
 
and
 
civil-society
 
networks.
 
The
 
profile
 
is
 
part
 
of
 
the
 
standard
 
API
 
licence
 
library.
 
It
 
can
 
be
 
switched
 
on
 
whenever
 
funders
 
or
 
governments
 
make
 
support
 
available,
 
without
 
rewriting
 
contracts
 
from
 
scratch.
 
For
 
the
 
provider,
 
the
 
profile
 
makes
 
it
 
easier
 
to
 
respond
 
to
 
procurement
 
rules
 
and
 
funding
 
schemes
 
that
 
require
 
demonstrable
 
public-interest
 
access.
 
For
 
public-interest
 
users,
 
it
 
creates
 
predictable,
 
medium-term
 
access
 
conditions
 
to
 
frontier
 
models,
 
backed
 
by
 
contractual
 
commitments
 
rather
 
than
 
one-off
 
discounts
 
or
 
pilots.
 
 
12
 


--- PAGE 13 ---

 
Example
 
3.4.2:
 
AI
 
Services
 
Marketplace
 
with
 
an
 
Access
 
Commons
 
Pool
 
A
 
platform
 
operates
 
a
 
marketplace
 
where
 
independent
 
developers
 
offer
 
specialised
 
AI
 
services:
 
document
 
analysis,
 
speech
 
recognition,
 
translation,
 
forecasting.
 
Each
 
service
 
is
 
licensed
 
to
 
end-users
 
under
 
the
 
platform’s
 
standard
 
marketplace
 
terms.
 
Prices
 
are
 
set
 
by
 
providers;
 
the
 
platform
 
takes
 
a
 
percentage
 
fee.
 
Civil-society
 
organisations
 
and
 
small
 
public
 
actors
 
can
 
technically
 
use
 
the
 
marketplace,
 
but
 
face
 
the
 
full
 
commercial
 
tariff
 
and
 
fragmented
 
support.
 
Under
 
an
 
Access
 
Commons
 
logic,
 
the
 
platform
 
introduces
 
an
 
Access
 
Commons
 
profile
 
that
 
service
 
providers
 
may
 
opt
 
into.
 
Providers
 
that
 
select
 
this
 
profile
 
keep
 
their
 
usual
 
commercial
 
terms
 
for
 
most
 
users.
 
They
 
also
 
agree
 
to
 
contribute
 
a
 
small
 
fraction
 
of
 
gross
 
marketplace
 
revenue
 
from
 
their
 
service
 
into
 
an
 
“Access
 
Commons
 
pool”
 
managed
 
by
 
the
 
platform
 
under
 
defined
 
rules.
 
In
 
exchange,
 
their
 
services
 
become
 
visible
 
in
 
a
 
curated
 
“public-interest
 
catalogue”.
 
Accredited
 
public-interest
 
users
 
access
 
this
 
catalogue
 
through
 
a
 
separate
 
interface.
 
For
 
them,
 
the
 
marketplace
 
licence
 
applies
 
different
 
terms:
 
zero
 
or
 
reduced
 
marginal
 
prices
 
up
 
to
 
a
 
defined
 
usage
 
cap,
 
and
 
shared
 
support
 
channels
 
maintained
 
by
 
the
 
platform.
 
The
 
Access
 
Commons
 
profile
 
guarantees
 
non-discriminatory
 
access
 
to
 
this
 
interface
 
for
 
accredited
 
users
 
and
 
a
 
minimum
 
stability
 
period
 
for
 
the
 
subsidised
 
terms.
 
The
 
pool
 
created
 
by
 
small
 
contributions
 
from
 
many
 
services
 
finances
 
the
 
subsidy
 
and
 
common
 
support.
 
The
 
platform
 
adopts
 
this
 
structure
 
because
 
some
 
public
 
buyers
 
and
 
funders
 
begin
 
to
 
require
 
evidence
 
of
 
inclusive
 
access
 
conditions
 
in
 
procurement
 
and
 
grant
 
schemes,
 
and
 
because
 
it
 
can
 
manage
 
the
 
Access
 
Commons
 
pool
 
centrally
 
rather
 
than
 
negotiating
 
discounts
 
service
 
by
 
service.
 
Providers
 
opt
 
in
 
because
 
presence
 
in
 
the
 
public-interest
 
catalogue
 
brings
 
reputation
 
benefits
 
and
 
occasional
 
funded
 
projects,
 
while
 
the
 
financial
 
contribution
 
remains
 
modest
 
and
 
standardised.
 
Example
 
3.4.3:
 
Shared
 
Research
 
Compute
 
Facility
 
with
 
Reserved
 
Capacity
 
A
 
regional
 
research
 
consortium
 
operates
 
a
 
shared
 
compute
 
facility
 
for
 
AI
 
training
 
and
 
large-scale
 
simulations.
 
Universities
 
and
 
public
 
research
 
institutes
 
sign
 
participation
 
agreements
 
that
 
give
 
them
 
reserved
 
capacity
 
and
 
access
 
to
 
support
 
staff.
 
Institutions
 
in
 
wealthier
 
systems
 
can
 
afford
 
substantial
 
allocations;
 
smaller
 
universities
 
and
 
institutes
 
in
 
lower-income
 
settings
 
are
 
often
 
priced
 
out
 
or
 
relegated
 
to
 
ad
 
hoc,
 
low-priority
 
queues.
 
Under
 
an
 
Access
 
Commons
 
logic,
 
the
 
consortium
 
amends
 
its
 
participation
 
agreements
 
to
 
include
 
an
 
Access
 
Commons
 
profile.
 
Institutions
 
that
 
join
 
the
 
facility
 
with
 
significant
 
reserved
 
capacity
 
agree
 
that
 
a
 
defined
 
share
 
of
 
their
 
allocation—say,
 
five
 
to
 
ten
 
per
 
cent—is
 
pooled
 
into
 
a
 
common
 
Access
 
Commons
 
queue.
 
The
 
service
 
terms
 
for
 
this
 
queue
 
cap
 
usage
 
fees
 
at
 
a
 
low,
 
standard
 
rate
 
and
 
guarantee
 
a
 
minimal
 
level
 
of
 
technical
 
support
 
and
 
training.
 
Eligibility
 
for
 
the
 
Access
 
Commons
 
queue
 
is
 
limited
 
to
 
accredited
 
low-resource
 
institutions
 
and
 
doctoral
 
programmes
 
that
 
meet
 
criteria
 
set
 
by
 
the
 
consortium
 
and
 
funders.
 
These
 
institutions
 
sign
 
a
 
light-weight
 
access
 
agreement
 
that
 
mirrors
 
the
 
technical
 
and
 
support
 
conditions
 
of
 
the
 
main
 
facility,
 
but
 
only
 
for
 
jobs
 
submitted
 
through
 
the
 
Access
 
Commons
 
queue.
 
The
 
same
 
clause
 
pattern
 
is
 
used
 
when
 
new
 
institutions
 
join,
 
so
 
rules
 
and
 
expectations
 
remain
 
stable
 
over
 
time.
 
For
 
well-resourced
 
members,
 
the
 
profile
 
is
 
the
 
price
 
of
 
participation
 
in
 
a
 
publicly
 
supported
 
facility
 
and
 
aligns
 
with
 
funders’
 
expectations
 
around
 
capacity
 
sharing.
 
For
 
low-resource
 
institutions,
 
it
 
creates
 
a
 
predictable
 
route
 
to
 
meaningful
 
use
 
of
 
high-end
 
compute,
 
rather
 
than
 
occasional
 
favours.
 
The
 
Access
 
Commons
 
here
 
is
 
instantiated
 
in
 
a
 
family
 
of
 
participation
 
and
 
access
 
terms
 
that
 
reserve
 
capacity
 
 
13
 


--- PAGE 14 ---

 
bands
 
and
 
support
 
conditions
 
for
 
defined
 
user
 
groups,
 
instead
 
of
 
leaving
 
access
 
entirely
 
to
 
ability
 
to
 
pay
 
or
 
informal
 
arrangements.
 
3.5.
 
Reciprocity
 
Commons:
 
Recognising
 
and
 
Rewarding
 
Contributions
 
The
 
Reciprocity
 
Commons
 
logic
 
targets
 
the
 
many
 
contributions
 
that
 
enable
 
AI
 
systems
 
but
 
rarely
 
receive
 
structured
 
recognition
 
or
 
a
 
share
 
of
 
downstream
 
value.
 
These
 
contributions
 
include
 
open-source
 
code,
 
community-curated
 
datasets,
 
domain
 
expertise,
 
annotation
 
labour,
 
evaluation
 
exercises
 
and
 
safety
 
red-teaming.
 
Reciprocity
 
Commons
 
clauses
 
ask
 
whether
 
licence
 
terms
 
can
 
embed
 
patterns
 
for
 
acknowledging
 
these
 
inputs
 
and
 
routing
 
part
 
of
 
the
 
value
 
generated
 
by
 
AI
 
systems
 
back
 
along
 
the
 
chains
 
that
 
produced
 
them.
 
The
 
focus
 
on
 
the
 
licensing
 
layer
 
reflects
 
the
 
fact
 
that
 
it
 
is
 
at
 
this
 
boundary
 
that
 
commercial
 
use
 
of
 
a
 
system
 
is
 
authorised
 
and
 
where
 
payment
 
flows
 
are
 
defined.
 
Licences
 
can
 
be
 
written
 
to
 
require
 
that
 
certain
 
classes
 
of
 
contributors
 
be
 
recorded,
 
that
 
revenue
 
shares
 
or
 
bonuses
 
be
 
routed
 
through
 
defined
 
mechanisms,
 
and
 
that
 
high-level
 
information
 
about
 
these
 
flows
 
be
 
visible
 
to
 
others.
 
The
 
following
 
scenarios
 
explore
 
how
 
Reciprocity
 
Commons
 
profiles
 
could
 
function
 
in
 
AI
 
marketplaces
 
and
 
platforms
 
that
 
already
 
track
 
usage
 
and
 
payments
 
at
 
scale.
 
Example
 
3.5.1:
 
An
 
AI
 
Services
 
Marketplace
 
with
 
On-Chain
 
Reciprocity
 
A
 
network
 
of
 
companies
 
builds
 
speech-to-text
 
and
 
translation
 
models
 
for
 
public
 
helplines,
 
call
 
centres
 
and
 
accessibility
 
tools.
 
Many
 
contributions
 
sit
 
upstream:
 
open-source
 
libraries,
 
small
 
labs
 
curating
 
language
 
data,
 
accessibility
 
organisations
 
providing
 
speech
 
corpora,
 
call-centre
 
agents
 
annotating
 
errors,
 
independent
 
red-teamers.
 
Once
 
the
 
models
 
are
 
wrapped
 
into
 
profitable
 
SaaS
 
products,
 
most
 
of
 
these
 
contributors
 
see
 
none
 
of
 
the
 
downstream
 
revenue.
 
The
 
models
 
are
 
deployed
 
through
 
a
 
blockchain-based
 
marketplace
 
used
 
to
 
register
 
AI
 
systems,
 
log
 
usage
 
and
 
route
 
payments.
 
Under
 
a
 
Reciprocity
 
Commons
 
logic,
 
the
 
marketplace
 
introduces
 
a
 
standard
 
Reciprocity
 
Commons
 
licence
 
profile
 
for
 
models
 
traded
 
on
 
the
 
network.
 
Model
 
owners
 
retain
 
their
 
intellectual
 
property
 
and
 
set
 
prices
 
as
 
before,
 
but
 
by
 
opting
 
into
 
this
 
profile
 
they
 
accept
 
additional
 
obligations
 
on
 
how
 
contributions
 
are
 
recorded
 
and
 
how
 
some
 
revenues
 
are
 
shared.
 
The
 
licence
 
requires
 
that
 
any
 
model
 
registered
 
under
 
this
 
profile
 
include,
 
as
 
on-chain
 
metadata,
 
a
 
contribution
 
graph.
 
The
 
graph
 
lists
 
classes
 
of
 
contributors—upstream
 
library
 
projects,
 
data-curation
 
teams,
 
accessibility
 
NGOs,
 
red-teaming
 
groups—each
 
with
 
an
 
agreed
 
share
 
of
 
a
 
reciprocity
 
pool.
 
When
 
institutional
 
clients
 
license
 
the
 
model’s
 
API
 
or
 
on-premise
 
version,
 
their
 
contracts
 
incorporate
 
the
 
same
 
profile.
 
A
 
fixed
 
percentage
 
of
 
gross
 
usage
 
fees
 
is
 
routed,
 
via
 
a
 
smart
 
contract,
 
into
 
the
 
model’s
 
reciprocity
 
pool
 
and
 
then
 
split
 
according
 
to
 
the
 
contribution
 
graph.
 
High-level
 
inflows
 
and
 
outflows
 
are
 
visible
 
on-chain;
 
allocation
 
within
 
each
 
class
 
is
 
governed
 
by
 
off-chain
 
arrangements
 
agreed
 
by
 
those
 
contributors.
 
Adoption
 
rests
 
on
 
demand.
 
Public
 
bodies
 
and
 
platforms
 
that
 
procure
 
speech
 
and
 
translation
 
services
 
announce
 
that
 
they
 
will
 
favour
 
models
 
offered
 
under
 
a
 
recognised
 
Reciprocity
 
Commons
 
profile.
 
For
 
model
 
owners,
 
accepting
 
these
 
terms
 
becomes
 
the
 
route
 
into
 
those
 
contracts
 
and
 
a
 
way
 
to
 
signal
 
“fair”
 
AI
 
practices.
 
For
 
contributors,
 
the
 
contribution
 
graph
 
and
 
reciprocity
 
pool
 
create
 
a
 
channel
 
through
 
which
 
their
 
efforts
 
can
 
attract
 
a
 
share
 
of
 
downstream
 
value,
 
without
 
each
 
needing
 
separate
 
bargaining
 
power.
 
The
 
Reciprocity
 
Commons
 
exists
 
here
 
as
 
a
 
family
 
of
 
licence
 
profiles
 
that
 
require
 
marketplace
 
participants
 
to
 
acknowledge
 
contributions
 
and
 
route
 
part
 
of
 
the
 
resulting
 
cashflows
 
through
 
a
 
shared,
 
auditable
 
mechanism.
 
 
14
 


--- PAGE 15 ---

 
Example
 
3.5.2:
 
Publisher-Level
 
AI
 
Features
 
with
 
Author
 
Dividends
 
A
 
large
 
academic
 
publisher
 
licenses
 
its
 
journal
 
portfolio
 
and
 
platforms
 
to
 
universities
 
and
 
research
 
institutes.
 
It
 
also
 
offers
 
AI
 
features
 
on
 
top
 
of
 
standard
 
access:
 
literature
 
search,
 
summarisation,
 
citation
 
suggestions
 
and
 
drafting
 
support
 
within
 
the
 
publisher’s
 
own
 
interface.
 
These
 
tools
 
rely
 
heavily
 
on
 
the
 
publisher’s
 
corpus
 
and
 
on
 
continuous
 
feedback
 
from
 
users.
 
Subscription
 
and
 
platform
 
revenues
 
flow
 
to
 
the
 
publisher.
 
Individual
 
researchers
 
whose
 
articles
 
anchor
 
the
 
corpus
 
receive
 
no
 
additional
 
benefit
 
when
 
their
 
work
 
is
 
repeatedly
 
surfaced,
 
summarised
 
or
 
used
 
as
 
training
 
material
 
for
 
the
 
AI
 
features.
 
Under
 
a
 
Reciprocity
 
Commons
 
logic,
 
the
 
publisher
 
introduces
 
a
 
Reciprocity
 
Commons
 
licence
 
profile
 
for
 
institutions
 
that
 
subscribe
 
to
 
the
 
AI-enhanced
 
platform.
 
Access
 
rights
 
and
 
baseline
 
subscription
 
prices
 
remain
 
in
 
the
 
usual
 
range.
 
The
 
profile
 
adds
 
a
 
commitment
 
on
 
the
 
publisher’s
 
side:
 
a
 
defined
 
percentage
 
of
 
its
 
revenues
 
from
 
AI
 
features
 
is
 
allocated
 
to
 
an
 
“author
 
dividends
 
pool”
 
administered
 
under
 
transparent
 
rules.
 
Institutions
 
that
 
select
 
this
 
profile
 
can
 
report
 
their
 
expenditure
 
on
 
AI
 
features
 
as
 
contributing
 
to
 
a
 
recognised
 
author-support
 
scheme,
 
which
 
some
 
funders
 
and
 
assessment
 
bodies
 
begin
 
to
 
value.
 
The
 
licence
 
requires
 
the
 
publisher
 
to
 
maintain
 
an
 
author-level
 
usage
 
register
 
linked
 
to
 
the
 
AI
 
tools.
 
For
 
each
 
article,
 
the
 
register
 
tracks,
 
in
 
aggregated
 
form,
 
how
 
often
 
it
 
is
 
retrieved,
 
summarised
 
or
 
cited
 
through
 
AI
 
features.
 
Usage
 
indicators
 
are
 
approximate
 
rather
 
than
 
perfect,
 
but
 
they
 
provide
 
a
 
stable
 
basis
 
for
 
allocation
 
across
 
a
 
large
 
portfolio.
 
At
 
regular
 
intervals,
 
the
 
author
 
dividends
 
pool
 
is
 
distributed
 
to
 
eligible
 
authors
 
in
 
proportion
 
to
 
these
 
indicators,
 
with
 
a
 
floor
 
payment
 
to
 
ensure
 
that
 
less
 
frequently
 
surfaced
 
but
 
still
 
active
 
contributions
 
are
 
recognised.
 
Authors
 
participate
 
under
 
simple
 
terms
 
notified
 
at
 
acceptance,
 
which
 
confirm
 
their
 
eligibility
 
to
 
receive
 
dividends
 
from
 
the
 
pool
 
without
 
changing
 
the
 
underlying
 
copyright
 
transfer
 
or
 
licence
 
to
 
the
 
publisher.
 
Universities
 
adopt
 
the
 
Reciprocity
 
Commons
 
profile
 
where
 
funders
 
and
 
evaluation
 
frameworks
 
begin
 
to
 
ask
 
how
 
institutions
 
using
 
AI-assisted
 
publishing
 
platforms
 
support
 
the
 
researchers
 
whose
 
work
 
underpins
 
those
 
tools.
 
For
 
the
 
publisher,
 
the
 
profile
 
differentiates
 
the
 
platform
 
from
 
competitors
 
and
 
helps
 
pre-empt
 
conflict
 
over
 
AI
 
training
 
and
 
secondary
 
use
 
of
 
articles.
 
For
 
authors,
 
the
 
usage
 
register
 
and
 
dividends
 
pool
 
do
 
not
 
replace
 
salaries
 
or
 
core
 
funding,
 
but
 
they
 
create
 
a
 
direct,
 
recurring
 
channel
 
through
 
which
 
intensive
 
AI-mediated
 
use
 
of
 
their
 
publications
 
generates
 
supplementary
 
income,
 
anchored
 
in
 
the
 
licensing
 
terms
 
that
 
govern
 
institutional
 
access
 
to
 
the
 
AI-enhanced
 
platform.
 
Example
 
3.5.3:
 
Image-Generating
 
Platform
 
with
 
Style-Linked
 
Artist
 
Dividends
 
A
 
large
 
image-generating
 
platform
 
licenses
 
its
 
models
 
and
 
APIs
 
to
 
agencies,
 
brands
 
and
 
design
 
teams.
 
Users
 
generate
 
images
 
by
 
prompt,
 
often
 
asking
 
for
 
results
 
“in
 
the
 
style
 
of”
 
named
 
artists
 
or
 
using
 
prompts
 
that
 
clearly
 
evoke
 
recognisable
 
styles.
 
The
 
models
 
have
 
been
 
trained
 
on
 
vast
 
image
 
corpora
 
scraped
 
from
 
the
 
web
 
and
 
from
 
curated
 
sets.
 
Revenues
 
from
 
subscriptions,
 
API
 
calls
 
and
 
enterprise
 
licences
 
flow
 
to
 
the
 
platform.
 
Artists
 
whose
 
work
 
and
 
styles
 
have
 
informed
 
the
 
models
 
receive
 
no
 
structured
 
recognition
 
or
 
share
 
of
 
this
 
income.
 
Under
 
a
 
Reciprocity
 
Commons
 
logic,
 
the
 
platform
 
introduces
 
a
 
Reciprocity
 
Commons
 
licence
 
profile
 
for
 
customers
 
who
 
use
 
its
 
generative
 
features
 
at
 
scale.
 
Core
 
commercial
 
terms
 
remain
 
in
 
place.
 
The
 
profile
 
adds
 
a
 
commitment
 
on
 
the
 
platform’s
 
side:
 
a
 
defined
 
percentage
 
of
 
its
 
revenues
 
from
 
image
 
generation
 
under
 
this
 
profile
 
is
 
allocated
 
to
 
an
 
“artist
 
dividends
 
pool”
 
administered
 
under
 
transparent
 
rules.
 
Customers
 
who
 
select
 
the
 
profile
 
can
 
represent
 
their
 
use
 
of
 
AI-generated
 
imagery
 
as
 
aligned
 
with
 
a
 
recognised
 
artist-support
 
scheme,
 
which
 
some
 
brands,
 
public
 
buyers
 
and
 
cultural
 
funders
 
begin
 
to
 
value.
 
 
15
 

